{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computational Cognitive Neuroscience\n",
    "\n",
    "## Assignment 2 \n",
    "\n",
    "#### Douwe van Erp (s4258126) & Arianne Meijer - van de Griend (s4620135)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import chainer\n",
    "from chainer import cuda, Function, gradient_check, report, training, utils, Variable\n",
    "from chainer import datasets, iterators, optimizers, serializers\n",
    "from chainer import Link, Chain, ChainList\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "import utils\n",
    "import numpy as np\n",
    "from chainer.cuda import to_cpu\n",
    "from chainer.dataset import concat_examples\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition of the different models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO explanation neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FCNN1(Chain):\n",
    "    def __init__(self, n_out):\n",
    "        super(FCNN1, self).__init__()\n",
    "        with self.init_scope():\n",
    "            self.l1 = L.Linear(None, n_out)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        y = self.l1(x)\n",
    "        return y\n",
    "\n",
    "class FCNN2(Chain):\n",
    "    def __init__(self, n_units, n_out):\n",
    "        super(FCNN2, self).__init__()\n",
    "        with self.init_scope():\n",
    "            self.l1 = L.Linear(None, n_units)\n",
    "            self.l2 = L.Linear(None, n_out)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        h1 = F.relu(self.l1(x))\n",
    "        y = self.l2(h1)\n",
    "        return y\n",
    "\n",
    "class FCNN3(Chain):\n",
    "    def __init__(self, n_units, n_out):\n",
    "        super(FCNN3, self).__init__()\n",
    "        with self.init_scope():\n",
    "            self.l1 = L.Linear(None, n_units)\n",
    "            self.l2 = L.Linear(None, n_units)\n",
    "            self.l3 = L.Linear(None, n_out)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        h1 = F.relu(self.l1(x))\n",
    "        h2 = F.relu(self.l2(h1))\n",
    "        y = self.l2(h2)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO explanation convolutional network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CNN(Chain):\n",
    "    def __init__(self, n_units, n_out):\n",
    "        super(CNN, self).__init__()\n",
    "        with self.init_scope():\n",
    "            # 5 output channels, kernel size of 5, stride of 1, padding of 0\n",
    "            self.l_conv = L.Convolution2D(None, 5, 5, 1, 0)\n",
    "            self.l_fc = L.Linear(None, n_units)\n",
    "            self.l_out = L.Linear(None, n_out)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        h1 = F.max_pooling_2d(self.l_conv(x), 5, 1, 0)\n",
    "        h2 = F.relu(self.l_fc(h1))\n",
    "        y = self.l_out(h2)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO explanation extended network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model iwth additional components (e.g. one of dropout, batch normalization, other activation functions, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance deep neural networks\n",
    "TODO visualise, interpret the results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(model):\n",
    "    max_epoch = 20\n",
    "    train_loss = []\n",
    "    val_loss = []\n",
    "    \n",
    "    while train_iter.epoch < max_epoch:\n",
    "    \n",
    "        # Next minibatch\n",
    "        train_batch = train_iter.next()\n",
    "        image_train, target_train = concat_examples(train_batch)\n",
    "    \n",
    "        # Feedforward pass\n",
    "        prediction_train = model(image_train)\n",
    "    \n",
    "        # Softmax cross entropy loss\n",
    "        loss = F.softmax_cross_entropy(prediction_train, target_train)\n",
    "    \n",
    "        # Backpropagation\n",
    "        model.cleargrads()\n",
    "        loss.backward()\n",
    "    \n",
    "        # Update all the trainable paremters\n",
    "        optimizer.update()\n",
    "    \n",
    "        # Check the validation accuracy of prediction after every epoch\n",
    "        if train_iter.is_new_epoch:\n",
    "    \n",
    "            # Display the training loss\n",
    "            print('epoch:{:02d} train_loss:{:.04f} '.format(train_iter.epoch, float(to_cpu(loss.data))), '')\n",
    "    \n",
    "            train_loss.append(float(to_cpu(loss.data)))\n",
    "    \n",
    "            test_losses = []\n",
    "            test_accuracies = []\n",
    "            while True:\n",
    "                test_batch = test_iter.next()\n",
    "                image_test, target_test = concat_examples(test_batch)\n",
    "    \n",
    "                # Forward pass\n",
    "                prediction_test = model(image_test)\n",
    "    \n",
    "                # Calculate the loss\n",
    "                loss_test = F.softmax_cross_entropy(prediction_test, target_test)\n",
    "                test_losses.append(to_cpu(loss_test.data))\n",
    "    \n",
    "                # Calculate the accuracy\n",
    "                accuracy = F.accuracy(prediction_test, target_test)\n",
    "                accuracy.to_cpu()\n",
    "                test_accuracies.append(accuracy.data)\n",
    "    \n",
    "                if test_iter.is_new_epoch:\n",
    "                    test_iter.epoch = 0\n",
    "                    test_iter.current_position = 0\n",
    "                    test_iter.is_new_epoch = False\n",
    "                    test_iter._pushed_position = None\n",
    "                    break\n",
    "    \n",
    "            print('val_loss:{:.04f} val_accuracy:{:.04f}'.format(np.mean(test_losses), np.mean(test_accuracies)))\n",
    "            \n",
    "            val_loss.append(np.mean(test_losses))\n",
    "            \n",
    "    return max_epoch, train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_training(epoch, train_loss, val_loss, title): \n",
    "    x = range(epoch)          \n",
    "    fig = plt.figure()\n",
    "    ax = plt.subplot(111)\n",
    "    \n",
    "    ax.plot(x, val_loss, 'r', label=\"Validation\")\n",
    "    ax.plot(x, train_loss, 'b', label=\"Training\")\n",
    "    \n",
    "    plt.xlabel('Epoch')\n",
    "    plt.xticks(range(epoch))\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title(title)\n",
    "    ax.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load data and iterators\n",
    "train, test = utils.get_mnist(n_train=100, n_test=100, n_dim=1, with_label=True)\n",
    "train_iter = iterators.SerialIterator(train, batch_size=32, shuffle=True)\n",
    "test_iter = iterators.SerialIterator(test, batch_size=32, repeat=False, shuffle=False)\n",
    "\n",
    "model = FCNN1(10,10)\n",
    "optimizer = optimizers.SGD()\n",
    "optimizer.setup(model)\n",
    "\n",
    "epoch, train_loss, val_loss = train_model(model)\n",
    "plot_training(epoch, train_loss, val_loss, '1-Layer Fully Connected Neural Network')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO report conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance convolutional neural network\n",
    "TODO visualise (plot loss), interpret the results + report conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load data and iterators\n",
    "train, test = utils.get_mnist(n_train=100, n_test=100, n_dim=3, with_label=True)\n",
    "train_iter = iterators.SerialIterator(train, batch_size=32, shuffle=True)\n",
    "test_iter = iterators.SerialIterator(test, batch_size=32, repeat=False, shuffle=False)\n",
    "\n",
    "model = CNN(64,10)\n",
    "optimizer = optimizers.SGD()\n",
    "optimizer.setup(model)\n",
    "\n",
    "epoch, train_loss, val_loss = train_model(model)\n",
    "plot_training(epoch, train_loss, val_loss, 'Convolutional Model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO report conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Biological plausibility of convolution\n",
    "TODO Explain in which ways convolution is biologically plausible and biologically implausible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance extended model\n",
    "TODO visualise, interpret the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train test, visualise, etc code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO Report if your new architecture outperforms the original convnet architecture.\n",
    "Provide a plot and a written explanation of your observed (better/worse) results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
