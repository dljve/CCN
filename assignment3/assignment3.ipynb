{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computational Cognitive Neuroscience\n",
    "\n",
    "## Assignment 3\n",
    "\n",
    "#### Douwe van Erp (s4258126) & Arianne Meijer - van de Griend (s4620135)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recurrent neural networks are able to deal with timeseries data, which is often the case in practical settings. To understand the basics of recurrent neural networks, please consult:\n",
    " \n",
    "- [Understanding LSTM Networks](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)\n",
    "- [A Gentle Tutorial of Recurrent Neural Network with Error Backpropagation](https://arxiv.org/pdf/1610.02583.pdf)\n",
    "\n",
    "In this assignment you will learn to implement a recurrent neural network consisting of \n",
    "\n",
    "- [x] one LSTM layer and a \n",
    "- [x] linear output layer. \n",
    "\n",
    "For training and testing you will use two instances of the create_data dataset which just computes as current output the sum of the two previous inputs.\n",
    "\n",
    "- [x] Note that you will have to make additional modifications. \n",
    "- [ ] define an RNN class, you need to \n",
    "- [x] define an iterator which works on sequential data. \n",
    "- [ ] replace the Classifier by a Regressor class since you are working with continuous output data. \n",
    "- [ ] Also your training loop needs to be adapted.\n",
    "- [ ] You need to accumulate loss over multiple time steps and you need to reset your network state starting at each epoch.\n",
    "\n",
    "\n",
    "    1.[ ] Implement an RNN and plot the training and test loss on the toy data as a function of epoch number.\n",
    "    2.[ ] Run your network for 100 time steps on test data; plot the predicted sum and the actual sum as a function of time.\n",
    "\n",
    "## TODO\n",
    "- Fix bug about _children\n",
    "- Play with network size\n",
    "- Replace Classifier by Regressor - Because the assignment says so!\n",
    "- Adapt training loop\n",
    "- New loss -> Accumulated loss over multiple setps each epoch\n",
    "- Check plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import chainer\n",
    "from chainer import cuda, Function, gradient_check, report, training, utils, Variable\n",
    "from chainer import datasets, iterators, optimizers, serializers\n",
    "from chainer import Link, Chain, ChainList\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "import utils\n",
    "import numpy as np\n",
    "from chainer.cuda import to_cpu\n",
    "from chainer.dataset import concat_examples\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the data\n",
    "Given code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_data(n=3000):\n",
    "\n",
    "    X = np.random.rand(n,1).astype('float32')\n",
    "    T = np.sum(np.hstack((X[0:-1],X[1:])),axis=1)\n",
    "    T = np.hstack([0, T[0:]]).astype('float32')\n",
    "    T = T.reshape([n,1])\n",
    "\n",
    "    return X, T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Definition Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(Chain):\n",
    "    def __init__(self,n_in, n_h1, n_h2, n_out):\n",
    "        with self.init_scope():\n",
    "            self.embed = L.EmbedID(n_in, n_h1)\n",
    "            self.mid = L.LSTM(n_h1, n_h2)  # the LSTM layer\n",
    "            self.out = L.Linear(n_h2, n_out)  # the feed-forward output layer\n",
    "            \n",
    "    def __call__(self, x):\n",
    "        h1 = self.embed(x)\n",
    "        h2 = self.mid(h1)\n",
    "        y = self.out(h2)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definition sequential iterator\n",
    "From [here](https://docs.chainer.org/en/stable/tutorial/recurrentnet.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ParallelSequentialIterator(chainer.dataset.Iterator):\n",
    "    def __init__(self, dataset, batch_size, repeat=True):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.epoch = 0\n",
    "        self.is_new_epoch = False\n",
    "        self.repeat = repeat\n",
    "        self.offsets = [i * len(dataset) // batch_size for i in range(batch_size)]\n",
    "        self.iteration = 0\n",
    "\n",
    "    def __next__(self):\n",
    "        length = len(self.dataset)\n",
    "        if not self.repeat and self.iteration * self.batch_size >= length:\n",
    "            raise StopIteration\n",
    "        cur_words = self.get_words()\n",
    "        self.iteration += 1\n",
    "        next_words = self.get_words()\n",
    "\n",
    "        epoch = self.iteration * self.batch_size // length\n",
    "        self.is_new_epoch = self.epoch < epoch\n",
    "        if self.is_new_epoch:\n",
    "            self.epoch = epoch\n",
    "\n",
    "        return list(zip(cur_words, next_words))\n",
    "\n",
    "    @property\n",
    "    def epoch_detail(self):\n",
    "        return self.iteration * self.batch_size / len(self.dataset)\n",
    "\n",
    "    def get_words(self):\n",
    "        return [self.dataset[(offset + self.iteration) % len(self.dataset)]\n",
    "                for offset in self.offsets]\n",
    "\n",
    "    def serialize(self, serializer):\n",
    "        self.iteration = serializer('iteration', self.iteration)\n",
    "        self.epoch = serializer('epoch', self.epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(model):\n",
    "    max_epoch = 20\n",
    "    train_loss = []\n",
    "    val_loss = []\n",
    "    \n",
    "    while train_iter.epoch < max_epoch:\n",
    "    \n",
    "        # Next minibatch\n",
    "        train_batch = train_iter.next()\n",
    "        image_train, target_train = concat_examples(train_batch)\n",
    "    \n",
    "        # Feedforward pass\n",
    "        prediction_train = model(image_train)\n",
    "    \n",
    "        # Softmax cross entropy loss\n",
    "        loss = F.softmax_cross_entropy(prediction_train, target_train)\n",
    "    \n",
    "        # Backpropagation\n",
    "        model.cleargrads()\n",
    "        loss.backward()\n",
    "    \n",
    "        # Update all the trainable paremters\n",
    "        optimizer.update()\n",
    "    \n",
    "        # Check the validation accuracy of prediction after every epoch\n",
    "        if train_iter.is_new_epoch:\n",
    "    \n",
    "            # Display the training loss\n",
    "            print('epoch:{:02d} train_loss:{:.04f} '.format(train_iter.epoch, float(to_cpu(loss.data))), '')\n",
    "    \n",
    "            train_loss.append(float(to_cpu(loss.data)))\n",
    "    \n",
    "            test_losses = []\n",
    "            test_accuracies = []\n",
    "            while True:\n",
    "                test_batch = test_iter.next()\n",
    "                image_test, target_test = concat_examples(test_batch)\n",
    "    \n",
    "                # Forward pass\n",
    "                prediction_test = model(image_test)\n",
    "    \n",
    "                # Calculate the loss\n",
    "                loss_test = F.softmax_cross_entropy(prediction_test, target_test)\n",
    "                test_losses.append(to_cpu(loss_test.data))\n",
    "    \n",
    "                # Calculate the accuracy\n",
    "                accuracy = F.accuracy(prediction_test, target_test)\n",
    "                accuracy.to_cpu()\n",
    "                test_accuracies.append(accuracy.data)\n",
    "    \n",
    "                if test_iter.is_new_epoch:\n",
    "                    test_iter.epoch = 0\n",
    "                    test_iter.current_position = 0\n",
    "                    test_iter.is_new_epoch = False\n",
    "                    test_iter._pushed_position = None\n",
    "                    break\n",
    "    \n",
    "            print('val_loss:{:.04f} val_accuracy:{:.04f}'.format(np.mean(test_losses), np.mean(test_accuracies)))\n",
    "            \n",
    "            val_loss.append(np.mean(test_losses))\n",
    "            \n",
    "    return max_epoch, train_loss, val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_training(epoch, train_loss, val_loss, title): \n",
    "    x = range(epoch)          \n",
    "    fig = plt.figure()\n",
    "    ax = plt.subplot(111)\n",
    "    \n",
    "    ax.plot(x, val_loss, 'r', label=\"Validation\")\n",
    "    ax.plot(x, train_loss, 'b', label=\"Training\")\n",
    "    \n",
    "    plt.xlabel('Epoch')\n",
    "    plt.xticks(range(epoch))\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title(title)\n",
    "    ax.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 100\n",
    "n_train = 3000\n",
    "n_test = 3000\n",
    "train_data = create_data(n_train)\n",
    "test_data = create_data(n_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RNN' object has no attribute '_children'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-2d2e6908af6d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mn_in\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_h1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_h2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_in\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_h1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_h2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_out\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-00e45b8f0e5b>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, n_in, n_h1, n_h2, n_out)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_in\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_h1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_h2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_out\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEmbedID\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_in\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_h1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_h1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_h2\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# the LSTM layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_h2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_out\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# the feed-forward output layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mQ:\\Anaconda3\\envs\\ccn\\lib\\site-packages\\chainer\\link.pyc\u001b[0m in \u001b[0;36m__setattr__\u001b[1;34m(self, name, value)\u001b[0m\n\u001b[0;32m    659\u001b[0m                     'cannot register a new link %s: attribute exists' % name)\n\u001b[0;32m    660\u001b[0m             \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 661\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_children\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    662\u001b[0m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mChain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    663\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'RNN' object has no attribute '_children'"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "train_iter = ParallelSequentialIterator(train_data, batch_size)\n",
    "test_iter = ParallelSequentialIterator(test_data, 1, repeat=False)\n",
    "\n",
    "n_in, n_h1, n_h2, n_out = 1000, 100, 50, 1000\n",
    "model = RNN(n_in, n_h1, n_h2, n_out)\n",
    "optimizer = optimizers.SGD()\n",
    "optimizer.setup(model)\n",
    "\n",
    "epoch, train_loss, val_loss = train_model(model)\n",
    "plot_training(epoch, train_loss, val_loss, 'RNN accumulated loss per epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
